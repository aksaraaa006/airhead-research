\documentclass[11pt]{article}

\usepackage{acl-ijcnlp2009}

\usepackage{epsfig}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}

\title{Discovering Analogous Pairs of Words using WordNet and PageRank}


\author{First Author\\
  Affiliation / Address line 1\\
  Affiliation / Address line 2\\
  {\tt email@domain}  \And
  Second Author\\
  Affiliation / Address line 1\\
  Affiliation / Address line 2\\
  {\tt  email@domain}}

\date{}

\begin{document}

\maketitle

\begin{abstract}

We present an unsupervised algorithm for identifying analogous pairs of concepts
based on corpus statistics and PageRank.  \emph{Some sentence here on the
  general context of the paper.} The algorithm uses context to identify word
pairs that are most likely to share the same relation.  To move from words to
concepts, for each grouping of analogous word pairs we build a graph of all the
possible senses and apply the PageRank algorithm to determine which are most
likely.  We test how analogous are the resulting lists of concepts with the SAT
analogy questions used in \cite{turney03combining}.  \emph{Some closing sentence
  here about what we found out based on the results.}


\end{abstract}

\section{Introduction}

Humans are adept at discovering analogous relationships between pairs of
concepts.  The concepts may be closely related such as ``fish swim in the sea;
birds fly in the sky,'' or unrelated ``electrons orbit protons; plants orbit
stars.''  There has been much work on how computers might emulate this {\bf
  discovery process}\cite{gentner83structure}.  \emph{Either cite a bunch of
  things here, or add a short setence or two describing the work}.  Furthermore,
recent work has show how text-only based approaches can identify analogous words
or concepts\cite{mangalath04analogy,turney05corpus,bicici06clustering}.  We
propose a novel algorithm for identifying analogous pairs of concepts by
combining at context statistics for word usage and PageRank\cite{brin98anatomy}
to determine what concepts those words represents.

{\bf This paragraph should outline the specifics of what problem is addressed in
  this paper.  This paragraph must catch the reader/reviewrs attention and make
  them believe the problem is important.}

A significant challenge with generating analogies directly from text is that
standard english writing does not frequently contain phrases such as ``\emph{a}
is to \emph{b} as \emph{c} is to \emph{d}``.  Another which occurs in writings
is a lack of comparable contexts, such that if you are given a $noun\_verb\_noun$
triple, there are few occurances of $*\_verb\_noun$ and $noun\_verb\_*$, and
even fewer occurances of $noun\_otherverb\_noun$.  An important contribution of
this paper is the use of the Open Mind Common Sense \cite{havasi07conceptnet} 
collection of common sense facts.

Additionally, we handle the issue of many potential meanings for words by
combining new approaches to Word Sense Disambiguation, which not only provides
more accuate relations, but can also reduce the scope of our problem. 
\begin{enumerate}
  \item Writing does not often contain explicit phrases of the type ``\emph{a}
    is to \emph{b} as \emph{c} is to \emph{d}''
  \item Even when we look for words that appear in simiar context, there  may
    not be many occurrences.
  \item words can take on a number of meanings, so a solution must be more than
    just extraction context-related words
\end{enumerate}

{\bf Next, we outline our proposed solution and how we address the problems in
  the previous paragraph.  We should give a motivating example here}  

Our hypothesis is that Pairs of words that appear in similar semantic contexts
are likely to share some relation to each other.  In this paper we focus
specifically on pairs of nouns that are likely to share a relation when the
pairs or their synonyms occur in the presence of verbs with similar semantics.  

\emph{This could be a footnote:} Note that our approach does not extract what the
specific relationship is between concepts.  Determining the relation is a task
of language generation and could require significant background knowledge for
complex relationships, both of which is outside the current scope of the task.

{\bf Then we need to frame our work in the existing body of work and state how
  we will measure up to prior examples.  Stating what we can use the work for is
  also a plus.}

The general outline of our paper is as follows.  Section \ref{sec:background}
covers background material on WordNet and Open Mind Common Sense.  Section
\ref{sec:identifying} outlines our approach in identifying analous pairs and
section \ref{sec:evaluation} evaluates the results.  Last, section
\ref{sec:background} reviews related work and section \ref{sec:discussion}
addresses the results and future work.

\section{Background}
\label{sec:background}

Our analogy discovery system makes use of two well established databases of
knowledge, WordNet \cite{fellbaum98wordnet} and the Open Mind Common Sense
\cite{havasi07conceptnet} collection.  Both of these provide suitable search
spaces for analogous noun-noun pairs, and a means of putting a reasonable scope
to the problem.

Wordnet \cite{fellbaum98wordnet} is a commonly used Lexical database, primarily used for Word Sense
Disambiguation.  For all open class words, such as nouns and verbs, WordNet
contains a collection of synsets which represent possible meanings of a
particular word.  For instance, the word car could refer to an automobile,
typically with 4 wheels, or it could also refer to a wheeled vehicle for use on
railroad lines.  Each of these possible meanings is reprensented as a synset,
which encompasses a collction of words which have the same meaning.

WordNet is further organized to include various relations between synsets, the
most important of which are: Hypernym, which provides a more general synset;
and Hyponym, which provides a more specific synset.  Additionally WordNet
contains relations for similar-to relations, meronymy, holonymy, and more, but
we primarily focus only on hyponyms and hypernyms.  Traditionally this is called
the IS-A hierarchy.

While WordNet is an excellent resrouce for WSD, it alone does not provide enough
information to generate analogies.  For the purpose of extracting potential
noun-noun pairs which can participate in an analogy, we make use of the Open
Mind Common Sense.  The facts in OMCS are written in a simplified version of
english which provides a vast amount of facts and relations between concepts.
These facts are primairly collections of attributes for a particular topic, such
facts as: ``paper is white```, ``paper is for writing on``, etc.  Due to the
simplified english, and wide range of provided relations, OMCS appears to be an
excellent resource for analogy generation, and has been used in similar projects
\cite{speer08analogyspace}.  From OMCS, we make use of approximately 130,000
$noun\_verb\_noun$ triplets, which is a reasonable sized corpus for discovering
groups of related noun-noun pairs.


Initially, other corpora were explored in the hopes of extracting suitable
analogies.  A variety of books from Project Gutenberg were explored, Moby Dick,
Childrens Novels, Paradise Lost, etc.  Unfortunately, due to the advanced use of
english in the majority of these texts we ran into several problems.  The first
problem encountered as a lack of sensible $noun\_verb\_noun$ triplets from the
corpora.  Second, we were unable to find additional examples of triplets based
on synonyms of nouns and verbs, which left a remarkable small search space for
real world examples, leaving the discovery of analogies to traversal of WordNet
relations, which is perhaps beyond the scope of WordNet's intended usage.

\section{Identifying Analogous Pairs}
\label{sec:identifying}

\emph{Insert general introductory paragraph that oulines the algorithm and how
  it will be broken up and explained}.

We are interested in determining if there exists a relationship between a pair
of nouns, which is dependent on identifying the semantic context in which the
nouns are used.  We use the verb as the key indicator of context and a good
starting point for identifying a possible noun-noun relation.  The general theme
of the algorithm is that two pairings of nouns will share a relation when the
nouns or their synonyms occur in the presence of verbs with similar semantics.
Consider the following sentences:
\begin{enumerate}
  \item The thisty man guzzled the water.
  \item The old car guzzled gas quickly.
\end{enumerate}

In a simple case such as this, the relation between man and water is the same as
the relation between car and gas.  It might also be true that the car, gas
relation mighthold to other things which a man might guzzle, or beings which
might guzzle water.  To account for this, our approach is to expand a potential
noun-noun pair by searching the corpus itself for other noun-noun pairs which
might have a similar meaning according to context.

This process takes place in three major steps
\begin{enumerate}
  \item Identify candidate noun-noun pairs
  \item Expanding each noun-noun pair
  \item Remove expanded pairs which are unrelated
  \item Categorize the expanded pairs for comparison
\end{enumerate}

The following subsections will cover each step is more detail.

\subsection{Generating Candidate Analogies}

This paragraph should focus on the first step $noun\_verb\_noun$ extraction from the corpus.
We allow that nouns may be separated from the verb by one or more word of
non-noun parts of speech.  We also filter out the nouns in prepositional
phrases.  Last, we allow nouns to be collocations, e.g. ``white house''.

\subsection{Moving From Word to Concept}

Once a list of $n_1\_v\_n_2$ triplets have been extracted from the corpus, we need to
expand each triplet to it's set of extended relations.  This \emph{expansion
list} should contain additional $n\_v\_n$ triplets which share the same verb,
and one of the nouns, or possibly it's synonym.  The process of expanding a
single triplet into other related triplets has the chance of producing not only
a large number of additional triplets, but some which do not have the same
relation.  

The first step of expansion is to search the corpus for other triplets which match
the pattern of $n_1\_v\_*$ and $*\_v\_n_2$.  This step finds contextual
selectors, similar to \cite{schwartz08selectors}, in the corpus itself for each of
the nouns present in the intial triplet.  The triplets constructed from the
selectors should have some analogous relationship, for example "pills are 
medicine" would likely have "penicillin is medicine", yet also could expand to
"laughter is medicine" which does not quite hold the same relation as the
previous two triplets.  

With this vast number of potentially analgous $noun\_verb\_noun$ triplets, a
simple unsupervised approach needs to be taken to determine that within this
small context, the meaning of each noun, and especially the verb, is the same
within all of the generated triplets.  Any triplet which is not found to be
closely related to the other present in the \emph{expansion list} can then be
removed.  To this end, we chose to make use of PageRank when applied to
WSD.  The rest of this section will focus on how the graph is built, and how
it's computation reflects on the \emph{expansion list}.

Our use of PageRank is an extension of it's application towards WSD,
\cite{mihalcea04wsdpagerank,mihalcea06randomwalks}.  For each word in
the \emph{expansion list}, we obtain the first three possible synsets for the word and
add edges from each competeing synset to all other synsets currently in the
graph based on the semantic similarity as defined by
\cite{banerjee03extendedgloss}.  One detail to note, is that candidate synsets
for a given word are only added to the graph onces, regardless of the number of
times it occurs in the extension list, and these candidate synsets are not
given edges to each other. 

The semantic similarity metric defined by \cite{banerjee03extendedgloss} gives a
score based on the gloss overlap of two synsets, along with gloss overlap of
their respective hyponyms and hypernyms.  This approach has been shown to give a
stronger similarity metric than other gloss based measures.  Their approach can be extended to take
into account additional WordNet relations, but we only evaluate the hyponym and
hypernym glosses in addtion to the synset glosses themselves.  The formulate
used is as follows:

\small
$similarity(A, B) = score(gloss(A), gloss(b)) + score(hyper(A), hyper(B)) +
score(hypo(A), hypo(B)) + score(hyper(A), gloss(B)) + score(gloss(A), hyper(B))
$

\normalsize
Where the score function is a sum of the number of words overlapping in the two
definitions, giving a higher weight to longer sequences of words which match.
For the hypernym and hyponym relations, we take only the first hypernym or hyponym
synset given by wordnet, as opposed to concatening each of their glosses together.  

Once the graph has been built with all the possible sense of each word that
occurs in the \emph{expansion list}, an arbitrary score is assigned to each node in the
graph.  This score will represent the importance of the particular synset, such
that a higher score implies that the synset is more fitting for the word given
the context, and conversely a lower score implies that the synset would not be a
fitting sense.  Note that since PageRank will rely on converging the score for
each node, the initial scores do not affect the final value, instead they only
affect the number of iterations needed for convergence.  For simplicity, we
select initial values of 1 for every node.  

Since our graph assigns edge weights to every edge between 
synsets, and each edge is un directed, we iteratively update the scores for each
synset with algorithm as follows, which is adapted from \cite{mihalcea06randomwalks}.   

\small
\[PR(V_i) = (1-d) + d*\sum_{V_j \in Edge(V_i)} w_{ij} \frac{PR(V_j)}
   {\displaystyle\sum_{V_k \in Edge(V_j)} w_{jk}}
   \]
\normalsize

This update will until for each node \(V_i\) the difference \(PR^{K+1}(V_i)
- PR^{K}(V_i)\), is less than some threshold, where ours is \(10^{-6}\).
Typically, this can be done in lesss than 40 iterations through the graph.

The final step utilizing PageRank and the \emph{expansion list} is filtering out all $noun\_verb\_noun$
triplets which are not semanticly related to the others.  To start, each noun that occured
in the \emph{expansion list} is given a score according to the number of synsets
for the word which have a pagerank score above some threshold \(t\).  Then, each
  $noun\_verb\_noun$ triplet is given a score based on the following equation:

\small
$ PairScore(nvn) = \frac {\displaystyle\sum_{w \in NounsOf(nvn)} {score(w) * count(w)}}
                          {\displaystyle\sum_{x \in UniqueWord(expansionList)}
                          {count(x)} * score(w)} $ 
\normalsize

This will assign some normalized score to each triplet in the \emph{expansion
list},
allowing us to easily filter out any triplets which have a score below some
threshold, in this case we selected \(.80\).  From this point on, the verbs are
left out of the \emph{expansion list}, and so each $noun\_verb\_noun$ triplet becomes a
$noun\_noun$ pair.

\subsection{Moving from Concepts to Categories}

An interesting piece of data we would like to extract from a generated
\emph{expansion list} is the dominating sense for all the first nouns in each
pair, and the dominating sense for all the second nouns in each pair.  Our hope
is that in general, most, if not all, of the nouns will map to the same general, but
not too general, hypernym.  This can easily be done by scoring each hypernym of
every synset in the \emph{expansion list}, or as follows:

\small
\[ HyperScore(s) = \displaystyle\sum_{w \in FirstNouns(expansionList)}
ParentScore(s, w) 
\]

\normalsize
where

\small
\[ ParentScore(synset, w) = \left\{ 
 \begin{array}{l l}
   {\frac {MaxDepth(synset)} {MaxDepth(w)}} & \mbox{if $synset$ in Hyper($w$)}\\
   0 & \mbox{else}\\
 \end{array} \right.
\]

\normalsize
This method will assign a score to each hypernym based on the number of times 

Which is done for the first nouns of pairs in the \emph{expansion list}, and a
second set of scores is computed using the same method for the second nouns of
pairs in the \emph{expansion list}.  The hypernym which is most likely to
dominate it's respective set of nouns would then be the synset with the highest
score.  
{\bf We may not get to trying this} One thought I had was to try to cluster
concepts from within the list itself.  We would still maintain the invariant
that all pairs are still analogous, but this would at least give us:
\begin{enumerate}
  \item a way of moving from concepts to categories, i.e. are there certain
    pairs of categories that are analogous?
  \item if we can extract categories, then we might be able to better identify
    new analogies.  For example, if we find that we have the categorical analogy
    ``animal:type'' and we see narwhal, we know it fits in the animal category
    even if we have never see ``narwhal'' or any of its synonyms.
\end{enumerate}

\section{Evaluation}
\label{sec:evaluation}

The important evaluation criteria is whether all the pairs in a generated set of
analogous pairs actually share the same relation.  We test this criteria using
SAT analogy questions of the form shown in figure \ref{fig:sat-question}.  A
question will provide an exemplar pair with a certain relation and a list of
possible analogous pairs; the correct answer requires identifying the option
with the pair that shares the same relationship.  For evaluation we use the 374
SAT analogy problems used in \cite{turney03combining}, which provide five
options to select from.  

\begin{figure}
  \begin{tabular}{lrl}
    \hline
    Provided example: & & mason:stone \\
    \hline
    Option & (a) & teacher:chalk \\
    & (b) & carpenter:wood  \\
    & (c) & soldier:gun \\
    & (d) & photograph:camera \\
    & (e) & book:word \\
    Solution & (b) & carpenter:wood  \\
    \hline
  \end{tabular}
  \caption{An example SAT analogy question.  Example reproduced from
    \cite{turney03combining}.}
  \label{fig:sat-question}
\end{figure}

\subsection{Rationale}

Our algorithm for selecting which option is summarized as choosing the set that
contains both the provided pair and the selected option, with possibilities for
substituting words in each pair with their synonyms.  We have purposefully kept
the algorithm for answering SAT analogy questions simple to focus primarily on
on evaluating the validity of the relationship within the sets and not on our
ability to correctly answer all the questions.  We find the information
retrieval concepts of precision and recall useful in this evaluation; we define
precision as a function of how well our algorithm does at producing a set with a
specific relationship, and recall as a function of the corpus.  If the algorithm
groups pairs with too broad of a relationship or no relationship at all, then
selecting the correct option from an SAT question will generate multiple false
positives.  However, if the corpus from which the sets are extracted does not
contain enough exemplars of a relationship, then the sets will be impoverished
and given an analogy question, no set will contain both the provided example and
one of the options.  Therefore, we provide two statistics, one for questions for
which the algorithm was able to find a set containing both the example and an
option (precision), and a second for which we were unable to find such a set.


\subsection{SAT Question Algorithm}

Our algoirthm for solving SAT-style analogy questions is as
follows. \emph{reword this all later.  This might be better presented using
  paragraphs}

\begin{enumerate}
  \item sets $S_1 \ldots S_n$ of analogous pairs are generated by the algorithm
  \item the input is a pair of words denoted $a:b$
  \item[] {\bf First determine which set contains pairs that have the same
    relation as the input.}
  \item for each synonym of $a$ and $b$, generate a new pair $a':b'$.
  \item find all pairs in the provided sets that match $a_i:y$ and $x:b_i$.  Let
    the set of mathes be $M$.
  \item for each pair $a_i:b_j \in M$ compute the Banerjee distance from $a$ to
    $a_i$ and $b$ to $b_i$ and find set that contains the pair with the lowest
    sum.  Let the resultings set me known as $X$ \emph{need a better name}.
    Note that if the input pair is in the provided sets, the distance will be 0
    and so the set containing the input pair will be used.
  \item If $|X| = 0$, return that no analogy could be found
  \item[] {\bf Second determine which option has the analogous relation.}
  \item for each option, $c:d$, generate a new pair $c':d'$ based on the
    synonyms of $c$ and $d$.
  \item find all pairs in $X$ that are of the form $c_i:y$ or $y:d_i$, and let
    this set be $N$
  \item for each pair $c_i:d_i \in N$, find the pair with the lowest Banerjee
    distance to the original option pair from which it was generated.  ({\bf
      What to do in case of ties?  Idea: use the option that is deepest in the
      tree?})    
  \item If $|N| = 0$ return that no analogy coudl be found.  Otherwise, select
    the option with the lowest distance.
\end{enumerate}
These Banerjee distance used in Steps ? and ? are weighting factors for the
semantic distance from the provided analogous pair.  We use these to account for
any differences in semantics when searching for the closest pair in the provided
sets

We allow synonyms of the all the pairs to account for some missing features in
the corpus.  \emph{more details and example here.}

\subsection{Results}

\emph{I sure hope these are good...; Save the analysis until the discussion
  section}

\section{Related Work}
\label{sec:related}

%Banerjee and Pedersen\cite{banerjee03extendedgloss} use the gloss (dictionary
%def.) provided by WordNet to determine simiarlity.  \emph{not sure if this even
%  goes here}.

Mangalath et al. extend LSA\cite{landauer88introduction} with a way determine
relation categories for word pairs\cite{mangalath04analogy}.  The authors define
ten types of relations and words that are describe the relations, e.g. the
relation synonymy and desciptors ``equivalent,'' ``equal,'' and ``match.''  For
each of these ten relations, the authors use LSA vectors to compute the cosine
similarity between the words and each provided pair and each alternative.  The
alternative whose similarities are most correlated with the provided pair is
selected as the answer.

Nakov and Hearst indentify the semantic relation between compound noun by seeing
what verbs might be used to related them\cite{nakov06using}.  Given some pair of
words that constitutes a compound noun, they search web pages for short phrases
where the two nouns are linked by a verb.  The types of verbs found indicate the
type of relationship between the nouns.  Unlike this work, no attempt is made to
automatically group noun pairs according to the relations they share. 

Silva et al. use Bayesian statistics to solve the problem of finding new pairs
that share a relation, given some example pairs that are known to share the same
relation\cite{silva07analogical}.  Their approach differs in that which concepts
are related is provided as background knowledge.  

Speer et al. also use the Open Mind Common Sense knowledge base (KB) to find
analogies\cite{speer08analogyspace}.  Natural language assertions are redefined
as a concept and a features; for example ``a trunk is a part of a car,'' is
turned into the concept``trunk'' with the feature ``part-of(car).''  The entire
KB is used to construct the matrix of concept $\times$ feature.  This matrix is
sparse due to missing data, and also may contain erroneous features due to
incorrect assertions in the KB.  Therefore, in order to smooth out the data, the
matrix is refactored using Singular Value Decomposition, keeping only a few
dimensions, SVD$_k(A) = U_kS_kV_k^{\top}$.  Concepts are represented as rows
in the $U_k$ matrix, and analogous concepts can be found by looking for those
concept vectors whose cosine similarity is highest.

Turney et al. combine several techniques for solving analogy questions and use a
weighting mechanism to achieve a better total accuracy than any of the
individual techniques alone\cite{turney03combining}.  The authors include common
techniques for comparing word similarity such WordNet relations (e.g. hypernyn,
meronym) and gloss overlap.  Another notable technique, the authors express the
realtionship between two words X and Y as a 128 element vector; the elements are
the frequencies returned by a search engine query of the form ``X $P$ Y'', where
$P$ is one of 128 predetermined relation-like phrases such as ``for,'' ``with,''
or ``in the.''  These phrases provide a closed-set of ways of relating the
nouns; in comparison, our approach uses verbs to relate, which makes a
vector-like representation impossible due to the open-class nature of verbs.  In
\cite{turney05corpus}, Turney and Littman use a similar vector representation
for words to solve analogy questions.

Bi\c{c}ici and Yuret extend the work by \cite{turney05corpus} by clustering the
vector representations of words\cite{bicici06clustering}.  The authors compute
multiple cluster segmentations using $k$-means and spectral clustering.  Analogy
questions are then answered by counting how many clusters contain both the query
pair and each option; the option that occurs most frequently with the querty
pair in the clusters is selected as the answer.  {\bf mention that they do worse
  than Turney?}

Veale also uses gloss overlap and the hypernym trees from WordNet as a part of
solving analogy questions\cite{veale04wordnet}.  Word sense similarity is
computed using a combination of exponentially-weighted gloss overlap and depth
of the common hypernym ancester of both senses.  Analogy questions are solved by
finding the choice pair with the highest similarity to the provided pair.

\section{Discussion}
\label{sec:discussion}

Hopefully we have good results and this section can focus on putting them in
context.  Key questions we can address are
\begin{enumerate}
  \item Why does this approach work?
  \item Are there cases where it doesn't work?
  \item Could we improve the SAT question answering algorithm?
  \item How does our model fit in with the rest of the field.  This point should
    draw upon all of the related work to paint a picture of the research
    landscape.  Can we combine our approach with others (e.g. use us as input
    for Sivla et al.), or adapt some techniques of other's papers?
  \item Aren't we just taking advantage of the knowledge contained in corpus (to
    some degree, yes)
  \item How we can improve this approach, i.e. future work.  One possibility is
    to move to analogous verbs, adjectives.  A second is to adapt the triplet
    extractor to be more general.  A third is to try to move to new specific
    domains, e.g. mine medical journal papers/abstracts to find analogous
    things.
\end{enumerate}

\section{Acknowledgements}

We should probably thank Peter Turney for the SAT Questions and Catherine Havasi
for giving us the OMCS data set.  Also, if we do, due to the double-blind
reviewing process we can't include it in the paper until the print copy since it
gives it away that we're not them.

\bibliographystyle{acl}
\bibliography{acl-ijcnlp2009}

\end{document}
